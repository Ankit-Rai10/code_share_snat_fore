from sklearn.metrics import mean_absolute_error, mean_squared_error
def fill_exogeneous_features_v2_stats(df, target_features, exog_ft, val_fh, debug=False):
    unique_id = df['unique_id'].unique()[0]
    columns_imputed = []
    df_summary = pd.DataFrame()
#     exog_ft_fourier = exog_ft

    n_trials = 10
    n_parallel = 1
    seed = 42
#     lags_to_consider = [1, 2, 3, 4, 12]

    for column in target_features:
        if debug:
            print(f"\nProcessing column: {column}")
            print(df[[column, 'ds']].tail(20))

        series = df[column]
        first_valid_pos1 = series.first_valid_index()
        if debug:
            print('First valid index:', first_valid_pos1)

        series.iloc[:first_valid_pos1] = 0
        nan_pos = series.isna().idxmax() if series.isna().any() else None

        if nan_pos is None:
            continue  # skip columns without NaNs

        n_nan = series.iloc[nan_pos:].isna().sum()
        if debug:
            print(f"n_nan: {n_nan}")
        
        # Prepare data
#         exog_ft_fourier = []
#         if apply_fourier:
#             uni_models = {
#                 'xgboost': AutoXGBoost(),
# #                  'autoridge': AutoRidge(),
# #                  'randomforest':AutoRandomForest(),
# #         'elasticnet':AutoElasticNet(),
#             }
#             period = 52
#             order = 4
#             fourier = Fourier(period=period, order = order)
#             fourier_features = fourier.in_sample(index = df['ds']).reset_index()
#             df_fourier = df.merge(fourier_features, on=['ds'], how='left')
# #             print(df.columns)
#             exog_ft_fourier = exog_ft+['sin(1,52)','cos(1,52)','sin(2,52)','cos(2,52)','sin(3,52)','cos(3,52)','sin(4,52)','cos(4,52)']
#             df_copy = df_fourier[['ds', 'unique_id', column]+exog_ft_fourier].copy()
#         else:
#             uni_models = {
# #                 'xgboost': AutoXGBoost(),
#                  'autoridge': AutoRidge(),
# #                  'randomforest':AutoRandomForest(),
#         'elasticnet':AutoElasticNet(),
#             }
        df_copy = df[['ds', 'unique_id', column]+exog_ft].copy()
        df_copy.rename(columns={column: 'y'}, inplace=True)
    

        # Split data
        train_data = df_copy.iloc[:len(df_copy)-n_nan-val_fh]
        val_data = df_copy.iloc[len(df_copy)-n_nan-val_fh:len(df_copy)-n_nan]
        test_data = df_copy.iloc[-n_nan:]
        train_holdout_data = pd.concat([train_data, val_data])
        if debug:
            print(f"Train: {train_data.shape}, Val: {val_data.shape}, Test: {test_data.shape}")
            
        print('------------------------calculating lags to consider--------------------------')
        periods, strength = get_best_lag_feats(train_data, unique_id=unique_id,column='y')
#         print(periods)
        lags_to_consider = [int(i) for i in periods]
        print('-------------------------lags and strengths calculated-----------------------')
        
        if len(exog_ft)==0:
            train_data = train_data[['ds','unique_id','y']]
        else:
            train_data = train_data
            X_df = val_data.drop(columns=['y'])

        # Train AutoML on train
        sf = StatsForecast(
                    models=[AutoARIMA(season_length = 5), AutoETS(season_length = 5)],
                    freq='W-FRI',
                    )
        
        # Forecast on validation
        if len(exog_ft)!=0:
            sf.fit(train_data)
            forecast_val_df = sf.predict(h=val_fh, X_df=X_df)
        else:
            sf.fit(train_data)
            forecast_val_df = sf.predict(h=val_fh) 
            
        merged_val = forecast_val_df.merge(val_data[['ds', 'y']], on='ds', how='left')
        merged_val.dropna(inplace=True)
#         print(merged_val)
        
        model_performance = []
        y_true = merged_val['y']
        for model in sf.models:
            model = str(model)
            print(merged_val.columns)
            if model in merged_val.columns:
                y_pred = merged_val[model]
                mae = mean_absolute_error(y_true, y_pred)
                rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                mape = np.mean(np.abs((y_true - y_pred) / np.clip(y_true, 1e-8, None))) * 100  # avoid division by 0
                model_performance.append((model, mae, rmse, mape))
        
        print('-------------------------- performance of all models ---------------------------')
        print(model_performance)
        
        best_model_name = min(model_performance, key=lambda x:x[3])[0]
        print('Best model = ',best_model_name)
#         print(sf)

        # Retrain on train+val
        
        
        
#         models_to_retrain = {
#             model_name: fcst.models_[model_name].models_[model_name]
#             for model_name in fcst.models_
#         }

#         fcst_final = MLForecast(
#             models=models_to_retrain,
#             lags=lags_to_consider,
# #             date_features=['month'],
#             freq='W-FRI',
#         ).fit(train_holdout_data[['ds', 'unique_id', 'y']+exog_ft], static_features=[], fitted=True)
#         X_df_fin = test_data
#         forecast_test_df = fcst_final.predict(h=n_nan,X_df=X_df_fin)
        
       
        if len(exog_ft)==0:
            train_holdout_data = train_holdout_data[['ds','unique_id','y']]
            sf.fit(train_holdout_data)
            forecast_test_df = sf.predict(h=n_nan)
        else:
            train_holdout_data = train_holdout_data
            X_df = test_data.drop(columns=['y'])
            print(X_df.columns)
            sf.fit(train_holdout_data)
            forecast_test_df = sf.predict(h=n_nan, X_df=X_df)
        
#         if len(exog_ft)!=0:
#             sf.fit(train_holdout_data)
#             forecast_val_df = sf.predict(h=n_nan, X_df=X_df)
#         else:
#             sf.fit(train_holdout_data)
#             forecast_val_df = sf.predict(h=n_nan) 
        
        
        
#         print('--------------forecast_val_df--------------------')
#         print(forecast_val_df)
#         print('------------------------forecast_test_df---------------')
#         print(forecast_test_df)

        if debug:
            fig, ax = plt.subplots(figsize=(12, 5))

            # Plot actual values
            ax.plot(df_copy['ds'], df_copy['y'], label='Actual', color='black', linewidth=2)

            # Plot validation forecasts
            for model_name in sf.models:
                model_name = str(model_name)
                if model_name in forecast_val_df.columns:
                    ax.plot(forecast_val_df['ds'], forecast_val_df[model_name],
                            linestyle='--', label=f'Val Forecast - {model_name}')

            # Plot test forecasts
            for model_name in sf.models:
                model_name = str(model_name)
                print(merged_val.columns)
                if model_name in forecast_test_df.columns:
                    ax.plot(forecast_test_df['ds'], forecast_test_df[model_name],
                            linestyle='-', label=f'Test Forecast - {model_name}')

            # Mark forecast start
#             ax.axvline(x=df_copy['ds'].iloc[len(df_copy) - n_nan], color='red', linestyle='--', label='Forecast Start')

            ax.set_title(f'{column} - Forecast Comparison Across Models')
            ax.set_xlabel("Date")
            ax.legend()
            ax.grid(True)
            plt.tight_layout()
            plt.show()
            
        


        replicate = forecast_test_df[best_model_name]
        df[column].iloc[nan_pos:] = replicate.values

        df_dummy = pd.DataFrame({
            'unique_id': unique_id,
            'Feature_Name': column,
            'n_imputations': n_nan,
            'MAE': mae,
            'RMSE': rmse,
            'MAPE': mape
        }, index=[0])

        df_summary = pd.concat([df_summary, df_dummy], ignore_index=True)
        columns_imputed.append(column)
#         print(df)

    print("Imputed columns:", columns_imputed)
    if debug:
        print("Summary:\n", df_summary)
#     print('----------Finally the features used are---------------------------')
#     print(exog_ft)

    return df, columns_imputed, df_summary
